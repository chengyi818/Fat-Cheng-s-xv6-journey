# 第六课 虚拟内存

## 提纲
1. 地址空间
2. 分页硬件

## 虚拟内存概览

### 虚拟内存要解决什么问题?
考虑这样一个问题,如果shell出现了bug:可能向随机的内存地址写数据.这时候我们必须保护内核和其他进程不被破坏,我们要怎么做?

### 解决方案: 隔离内存空间
1. 每个进程有专属于自己的内存空间
2. 进程可以读写自己的内存
3. 进程不能读写其他进程的内存或者内核内存空间

面临的挑战: 如何在一块物理内存上,实现这样的隔离.

### 分页硬件
1. xv6, jos甚至是Linux kernel都是通过x86提供的硬件分页功能,实现了内存隔离.
2. 分页硬件本质上是提供了一种间隔寻址的功能.
```
  CPU -> MMU -> RAM
      VA     PA
```
3. 软件或者更直接一点CPU执行指令操作的都是虚拟地址,而不是物理地址.
4. 内核在MMU中为每个进程分别保存了虚拟地址和物理地址的对应关系.
5. MMU本质上就是一个表,索引是虚拟地址,值是一个特定结构,被称为*page table*.
6. 通过MMU的flags标志位,可以限制每个进程能够访问的内存空间.

### x86分页大小
1. 每页大小为: 4KB.
2. 内存地址都是4KB对齐的
3. 因此*page table*可以使用虚拟地址中的前20bit就可以定位一个内存页.

### PTE的组成
1. 参考资料: x86_translation_and_registers.pdf
2. PTE前20bit代表对应页的物理地址,也被称为*physical page number*,简写为PPN.
3. MMU在将虚拟地址转换为物理地址的过程中,会将前20位虚拟地址替换为PPN.
4. 低位的12bit是标志位,表示存在,可写,用户进程是否可以访问等等.

### 如果页表仅由PTE组成,是否可行?
我们来计算这样一个页表的大小:
1. 索引项总数为2^20, 每项大小32bit.总计消耗内存为4MB.
2. 这对于早期的计算而已,消耗太大.
3. 事实上,这样的设计存在巨大的浪费.因为很多程序仅仅需要分配数百页内存.没必要在一开始就分配这么大的页表.

### x86 二级页表
1. 第一级是*page directory*(PD),简写为PDE.
2. PDE本身组成一个1024*32的表,一共占用4KB内存.
3. PDE高20位为PPN,指向一个PTE表.低12位为标志位.
4. 正是因为PDE存在标志位,因此可以节约PTE表的空间.
5. PTE表同样是一个1024*32的表,每个索引项可以指向1个内存页.

### MMU定位page table在内存中的位置
1. %cr3保存了page directory table的物理地址
2. page directory table保存了PTE的物理地址.
3. 这些地址在物理内存中可以是离散.

### 虚拟地址转换为物理地址
1. 目标就是找到虚拟地址对应的PTE.
2. %cr3指向PD所在的物理地址.
3. 通过虚拟地址的前10位索引PD,得到PT所在的物理地址.
4. 通过虚拟地址接下来的10位,索引PT得到PTE.
5. 通过PTE的PPN和虚拟地址的低12位,得到最终的物理地址.

### PTE标志位
1. 标志位包括P, W, U等等
2. xv6通过标志位U来阻止用户访问内核内存.

### 被访问PTE的标志位P未设置, 或存储时标志位W未设置
1. MMU硬件将会产生中断,抛出*page fault*异常
2. 处理中断时,CPU将会保存现场,也就是当前寄存器的值.同时将控制权移交给内核.
3. 一种处理方式是: 内核将会生成错误信息,同时杀掉异常进程.这种情况在我们刚开始学习写代码的时候很常见,尤其是做指针相关的练习的时候.
4. 另一种处理方式是: 如果是被置换到硬盘的内存,内核会将内存内容恢复,并更新PTE的内容.接着恢复异常进程.这种情况在Linux Kernel中经常会见到.

### 为什么要在虚拟地址和物理地址间建立映射关系,而不是基于起始地址做位移?
1. 避免碎片化
2. fork写时拷贝.
3. 延迟分配,即真正要用到的时候,在实际分配.
...

### 为什么在内核中也使用虚拟内存?
1. 出于隔离和保护的目的,很明显在用户空间使用虚拟内存是非常应该的.但是为什么在内核中,也要使用虚拟内存呢?内核可以直接使用物理内存运行么?
2. 内核可以直接使用物理内存运行,比如Singularity内核.
3. 以下是大多数现代内核使用虚拟内存的原因,其中一些不太站得住脚,有些有点道理,但是并没有什么不得不使用虚拟内存的原因.
  * 分页硬件难以关闭,比如每次系统调用的时候,内核处理前都要关闭分页硬件,在返回用户空间前,打开.这样比较繁琐.
  * 便于内核使用用户空间地址,比如通过系统调用将用户空间地址传递到内核中.但这同时减弱了内核和用户空间之间的隔离性.
  * 不易于产生内存碎片.比如我们想分配64KB内存,但是物理内存中并没有连续的64KB,使用虚拟内存可以将不连续的物理内存映射成连续的虚拟内存.
  * 内核必须兼容大多数硬件平台,它们的物理内存分布各式各样.通过虚拟内存可以屏蔽这些差异.
  
---

## 学习案例: xv6中的x86分页硬件

### xv6 进程地址空间
```
  0x00000000:0x80000000 -- user addresses below KERNBASE
  0x80000000:0x80100000 -- map low 1MB devices (for kernel)
  0x80100000:?          -- kernel instructions/data
  ?         :0x8E000000 -- 224 MB of DRAM mapped here
  0xFE000000:0x00000000 -- more memory-mapped devices
```

### xv6 物理内存映射关系
1. 重点关注用户空间的内存页其实被映射了两次.在内核页表中,被连续映射到了内核地址的高地址上.
2. 在用户空间申请时,内核正是根据自己申请到的虚拟地址减去内核地址基址kernel base,才得到了PPN.

### 每个进程都有独立的内存空间和页表
1. 所有进程共享相同的内核页表映射.
2. 内核切换进程时,同样会通过设置%cr3来切换进程页表.

### 用户进程布局












---
